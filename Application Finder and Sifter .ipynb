{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement/Goal\n",
    "\n",
    "Just how automated and easy can I make my job search?  As an individual who needs to work part time while looking for work, it's important that I releave some fo the stress and busy work of looking for a job. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from selenium import webdriver\n",
    "import selenium\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "#import regex as re\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working through list of potential techies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A while ago I gathered a list of tech startups from a few lists on the internet.  While I was going through the list to see which companies I'd like to apply to I realized that I could write a script to make the simple task of copy/pasting the title and googling properly automated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "techies = pd.read_csv('../../job_search/Terra\\'s Job Tracker - Potential Techies.csv')\n",
    "drop_columns = ['Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Possible?']\n",
    "techies.drop(drop_columns,  axis = 1, inplace = True)\n",
    "techies.fillna('empty', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Firm</th>\n",
       "      <th>Site</th>\n",
       "      <th>What They do</th>\n",
       "      <th>Interest</th>\n",
       "      <th>#'d Interest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accompany</td>\n",
       "      <td>empty</td>\n",
       "      <td>empty</td>\n",
       "      <td>Nope</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Advanced Metal Technology AG</td>\n",
       "      <td>empty</td>\n",
       "      <td>empty</td>\n",
       "      <td>empty</td>\n",
       "      <td>empty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Affirm</td>\n",
       "      <td>https://www.affirm.com/</td>\n",
       "      <td>empty</td>\n",
       "      <td>empty</td>\n",
       "      <td>empty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Altschool</td>\n",
       "      <td>https://www.altschool.com/</td>\n",
       "      <td>empty</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARSALIS</td>\n",
       "      <td>empty</td>\n",
       "      <td>empty</td>\n",
       "      <td>empty</td>\n",
       "      <td>empty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Firm                        Site What They do  \\\n",
       "0                     Accompany                       empty        empty   \n",
       "1  Advanced Metal Technology AG                       empty        empty   \n",
       "2                        Affirm     https://www.affirm.com/        empty   \n",
       "3                     Altschool  https://www.altschool.com/        empty   \n",
       "4                       ARSALIS                       empty        empty   \n",
       "\n",
       "  Interest #'d Interest  \n",
       "0     Nope            1  \n",
       "1    empty        empty  \n",
       "2    empty        empty  \n",
       "3      Yes            4  \n",
       "4    empty        empty  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "techies.head()#['What They do'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome('../../Garage/chromedriver')                     # Launches Browser\n",
    "\n",
    "for term in searchterm:\n",
    "browser.get('https://sfbay.craigslist.org/d/software-qa-dba-etc/search/sof')# Get Search page of Craigslist\n",
    "search = browser.find_element_by_id(\"query\")                                # Locate searchbar\n",
    "search.send_keys('data')                                                    # Input search\n",
    "search.submit() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accompany\n",
      "---------------------------------\n",
      "nonlinks:1\n",
      "headers:  15  URLs:  14\n",
      "link #:  0\n",
      "Accompany | People and company intelligence for executives.\n",
      "https://www.accompany.com/\n",
      "-----------------------------------------\n",
      "link #:  1\n",
      "\n",
      "\n",
      "-----------------------------------------\n",
      "link #:  2\n",
      "\n",
      "\n",
      "-----------------------------------------\n",
      "link #:  3\n",
      "\n",
      "\n",
      "-----------------------------------------\n",
      "link #:  4\n",
      "\n",
      "\n",
      "-----------------------------------------\n",
      "link #:  5\n",
      "Accompany | Definition of Accompany by Merriam-Webster\n",
      "https://www.merriam-webster.com/dictionary/accompany\n",
      "-----------------------------------------\n",
      "link #:  6\n",
      "Accompany | Define Accompany at Dictionary.com\n",
      "https://www.dictionary.com/browse/accompany\n",
      "-----------------------------------------\n",
      "link #:  7\n",
      "Accompany — purposeful lifestyle goods for the modern nomad\n",
      "https://www.accompanyus.com/\n",
      "-----------------------------------------\n",
      "link #:  8\n",
      "Accompany Synonyms, Accompany Antonyms | Thesaurus.com\n",
      "https://www.thesaurus.com/browse/accompany\n",
      "-----------------------------------------\n",
      "link #:  9\n",
      "accompany (verb) definition and synonyms | Macmillan Dictionary\n",
      "https://www.macmillandictionary.com/us/dictionary/american/accompany\n",
      "-----------------------------------------\n",
      "link #:  10\n",
      "ACCOMPANY | definition in the Cambridge English Dictionary\n",
      "https://dictionary.cambridge.org/us/dictionary/english/accompany\n",
      "-----------------------------------------\n",
      "link #:  11\n",
      "accompany | Definition of accompany in English by Oxford Dictionaries\n",
      "https://en.oxforddictionaries.com/definition/accompany\n",
      "-----------------------------------------\n",
      "link #:  12\n",
      "accompany - Wiktionary\n",
      "https://en.wiktionary.org/wiki/accompany\n",
      "-----------------------------------------\n",
      "link #:  13\n",
      "accompany - Dictionary Definition : Vocabulary.com\n",
      "https://www.vocabulary.com/dictionary/accompany\n",
      "-----------------------------------------\n",
      "Which link? 0\n",
      "\n",
      "Interest? sure\n",
      "Advanced Metal Technology AG\n",
      "---------------------------------\n",
      "nonlinks:1\n",
      "headers:  10  URLs:  9\n",
      "link #:  0\n",
      "Amtech-amt.com | Advanced Metal Technology, INC.\n",
      "https://www.amtech-amt.com/\n",
      "-----------------------------------------\n",
      "link #:  1\n",
      "Advanced Metal Technology AG in Liquidation, Zürich - Moneyhouse\n",
      "https://www.moneyhouse.ch › Home page › Company\n",
      "-----------------------------------------\n",
      "link #:  2\n",
      "Advanced Metal Technology AG in Liquidation, Zürich - Kontakt\n",
      "https://www.easymonitoring.ch/.../advanced-metal-technology-ag-8...\n",
      "-----------------------------------------\n",
      "link #:  3\n",
      "AMT - Advanced Metal Technologies | AcronymAttic\n",
      "https://www.acronymattic.com/Advanced-Metal-Technologies-(AMT).html\n",
      "-----------------------------------------\n",
      "link #:  4\n",
      "Advanced Metal Technology, Inc.: Private Company Information ...\n",
      "https://www.bloomberg.com/research/stocks/private/snapshot.asp?privcapId...\n",
      "-----------------------------------------\n",
      "link #:  5\n",
      "Marco Siegrist – Advanced Metal Technology AG - W.A. De Vigier ...\n",
      "www.devigier.ch/portfolio-item/marco-siegrist-advanced-metal-technology-ag/?lang...\n",
      "-----------------------------------------\n",
      "link #:  6\n",
      "AMT\n",
      "www.amt-mat.com/\n",
      "-----------------------------------------\n",
      "link #:  7\n",
      "Advanced Metal Technology - IT Services & Computer Repair - 4076 ...\n",
      "https://www.yelp.com/biz/advanced-metal-technology-yoncalla\n",
      "-----------------------------------------\n",
      "link #:  8\n",
      "Images for Advanced Metal Technology AG\n",
      "https://books.google.com/books?isbn=1351643681\n",
      "-----------------------------------------\n",
      "Which link? 0\n",
      "\n",
      "Interest? nah\n",
      "Affirm\n",
      "---------------------------------\n",
      "Altschool\n",
      "---------------------------------\n",
      "ARSALIS\n",
      "---------------------------------\n",
      "nonlinks:7\n",
      "headers:  13  URLs:  6\n",
      "link #:  0\n",
      "Arsalis is a spin-off of Université catholique de Louvain - Arsalis\n",
      "www.arsalis.com/\n",
      "-----------------------------------------\n",
      "link #:  1\n",
      "Contact us\n",
      "scholar.google.com/citations?user=dMfy0zgAAAAJ&hl=en\n",
      "-----------------------------------------\n",
      "link #:  2\n",
      "Force plate\n",
      "https://www.linkedin.com/company/arsalis\n",
      "-----------------------------------------\n",
      "link #:  3\n",
      "Treadmill\n",
      "emits.esa.int/emits/owa/!ViewData.baseData?pentityid=32779...O...\n",
      "-----------------------------------------\n",
      "link #:  4\n",
      "GLM\n",
      "https://www.researchgate.net › University of Cyprus\n",
      "-----------------------------------------\n",
      "link #:  5\n",
      "Gait analysis\n",
      "https://www.researchgate.net/.../317821095_Correction_Arsalis_A_Alexandrou_AN_Ge...\n",
      "-----------------------------------------\n",
      "Which link? 99\n",
      "Atrium LTS\n",
      "---------------------------------\n",
      "Aurora Innovation\n",
      "---------------------------------\n",
      "Auth0\n",
      "---------------------------------\n",
      "AutoFi\n",
      "---------------------------------\n",
      "AvidXchange\n",
      "---------------------------------\n",
      "Away\n",
      "---------------------------------\n",
      "Bellhops\n",
      "---------------------------------\n",
      "Bill.com\n",
      "---------------------------------\n",
      "Bio Boards Landsurf\n",
      "---------------------------------\n",
      "nonlinks:3\n",
      "headers:  10  URLs:  7\n",
      "link #:  0\n",
      "Videos\n",
      "https://www.facebook.com › ... › Sporting Goods Store\n",
      "-----------------------------------------\n",
      "link #:  1\n",
      "Bio Boards - Landsurf - Home | Facebook\n",
      "www.bio-boards.net/landsurf/\n",
      "-----------------------------------------\n",
      "link #:  2\n",
      "Custom Boards — Bio Boards\n",
      "www.bio-boards.net/\n",
      "-----------------------------------------\n",
      "link #:  3\n",
      "Bio Boards\n",
      "www.bio-boards.net/home/\n",
      "-----------------------------------------\n",
      "link #:  4\n",
      "LAND SURF - Home — Bio Boards\n",
      "https://www.starters.co/bioboardslandsurf\n",
      "-----------------------------------------\n",
      "link #:  5\n",
      "Bio Boards Landsurf | Starters\n",
      "https://www.linkedin.com/company/land-surf---bio-boards\n",
      "-----------------------------------------\n",
      "link #:  6\n",
      "Bio Boards - Landsurf | LinkedIn\n",
      "https://www.crunchbase.com/organization/bio-boards\n",
      "-----------------------------------------\n",
      "Which link? 2\n",
      "\n",
      "Interest? nah\n",
      "BioRobtics Lab.\n",
      "---------------------------------\n",
      "nonlinks:1\n",
      "headers:  11  URLs:  10\n",
      "link #:  0\n",
      "Biorobotics Lab\n",
      "biorobotics.ri.cmu.edu/index.php\n",
      "-----------------------------------------\n",
      "link #:  1\n",
      "UW BioRobotics Lab – A blog dedicated to the news and ...\n",
      "brl.ee.washington.edu/\n",
      "-----------------------------------------\n",
      "link #:  2\n",
      "Biorobotics Laboratory (BioRob) | EPFL\n",
      "https://biorob.epfl.ch/\n",
      "-----------------------------------------\n",
      "link #:  3\n",
      "Harvard Biorobotics Laboratory\n",
      "biorobotics.harvard.edu/\n",
      "-----------------------------------------\n",
      "link #:  4\n",
      "Biorobotics Lab - NUS Biomedical Engineering\n",
      "www.bioeng.nus.edu.sg/biorob/\n",
      "-----------------------------------------\n",
      "link #:  5\n",
      "SNU Biorobotics Lab\n",
      "biorobotics.snu.ac.kr/\n",
      "-----------------------------------------\n",
      "link #:  6\n",
      "Welcome to the Biorobotics Laboratory | Biorobotics Laboratory ...\n",
      "biorobotics.eng.uci.edu/\n",
      "-----------------------------------------\n",
      "link #:  7\n",
      "Biorobotics Laboratory | Just another UWM CampusPress WordPress ...\n",
      "people.uwm.edu/biorobotics-lab/\n",
      "-----------------------------------------\n",
      "link #:  8\n",
      "Berlin Biorobotics - Research in Collective Intelligence, Machine ...\n",
      "berlinbiorobotics.blog/\n",
      "-----------------------------------------\n",
      "link #:  9\n",
      "Biologically Inspired Robotics | Case Western Reserve University\n",
      "biorobots.cwru.edu/\n",
      "-----------------------------------------\n",
      "Which link? 0\n",
      "\n",
      "Interest? nah\n",
      "Brandless\n",
      "---------------------------------\n",
      "C3 IoT\n",
      "---------------------------------\n",
      "Carta\n",
      "---------------------------------\n",
      "Celmatix\n",
      "---------------------------------\n",
      "Citizen\n",
      "---------------------------------\n",
      "nonlinks:1\n",
      "headers:  11  URLs:  10\n",
      "link #:  0\n",
      "Citizen Watch US Official Site | Citizen\n",
      "https://www.citizenwatch.com/us/en/home\n",
      "-----------------------------------------\n",
      "link #:  1\n",
      "CITIZEN WATCH Global Network\n",
      "www.citizenwatch-global.com/\n",
      "-----------------------------------------\n",
      "link #:  2\n",
      "Home | Citizen Watch Europe\n",
      "https://www.citizenwatch.eu/\n",
      "-----------------------------------------\n",
      "link #:  3\n",
      "Citizen | Define Citizen at Dictionary.com\n",
      "https://www.dictionary.com/browse/citizen\n",
      "-----------------------------------------\n",
      "link #:  4\n",
      "Citizen | Definition of Citizen by Merriam-Webster\n",
      "https://www.merriam-webster.com/dictionary/citizen\n",
      "-----------------------------------------\n",
      "link #:  5\n",
      "citizen - Wiktionary\n",
      "https://en.wiktionary.org/wiki/citizen\n",
      "-----------------------------------------\n",
      "link #:  6\n",
      "Citizens Bank | Personal & Business Banking, Student Loans ...\n",
      "https://www.citizensbank.com/HomePage.aspx\n",
      "-----------------------------------------\n",
      "link #:  7\n",
      "Citizen - Home | Facebook\n",
      "https://www.facebook.com › Pages › Public Figure › Musician/Band\n",
      "-----------------------------------------\n",
      "link #:  8\n",
      "Citizen | Lunch. Dinner. Cocktails. Good for Groups and Parties.\n",
      "https://www.citizenbeverlyhills.com/\n",
      "-----------------------------------------\n",
      "link #:  9\n",
      "Citizenship - Wikipedia\n",
      "https://en.wikipedia.org/wiki/Citizenship\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which link? 99\n",
      "Cloudflare\n",
      "---------------------------------\n",
      "Coda\n",
      "---------------------------------\n",
      "Cohesity\n",
      "---------------------------------\n",
      "Coinbase\n",
      "---------------------------------\n",
      "Continuum Technotogies\n",
      "---------------------------------\n",
      "nonlinks:1\n",
      "headers:  11  URLs:  10\n",
      "link #:  0\n",
      "Continuum - IT Management, BDR and RMM Software Built for MSPs\n",
      "https://www.continuum.net/\n",
      "-----------------------------------------\n",
      "link #:  1\n",
      "Continuum Technologies | LinkedIn\n",
      "https://www.linkedin.com/company/continuumwear\n",
      "-----------------------------------------\n",
      "link #:  2\n",
      "Continuum Technologies Inc | LinkedIn\n",
      "https://www.linkedin.com/company/continuum-technologies-inc\n",
      "-----------------------------------------\n",
      "link #:  3\n",
      "Continuum Technologies\n",
      "https://www.continuumtech.ca/\n",
      "-----------------------------------------\n",
      "link #:  4\n",
      "Continuum Technologies | Revolutionising athletic performance and ...\n",
      "continuumtech.co.uk/\n",
      "-----------------------------------------\n",
      "link #:  5\n",
      "Welcome to Continuum Technologies, Inc.\n",
      "www.continuumtech.net/\n",
      "-----------------------------------------\n",
      "link #:  6\n",
      "Continuum Technologies, LLC | Better Business Bureau® Profile\n",
      "https://www.bbb.org/us/nj/lebanon/.../continuum-technologies-llc-0221-29004580\n",
      "-----------------------------------------\n",
      "link #:  7\n",
      "Continuum Technologies | Graphene-Info\n",
      "https://www.graphene-info.com › ... › Graphene application developers\n",
      "-----------------------------------------\n",
      "link #:  8\n",
      "Continuum Technologies | eBay Stores\n",
      "https://www.ebay.com/str/continuumtechnologies\n",
      "-----------------------------------------\n",
      "link #:  9\n",
      "Continuum Technologies Limited in IE | Key Information | DueDil\n",
      "https://www.duedil.com/company/ie/358414/continuum-technologies-limited\n",
      "-----------------------------------------\n",
      "Which link? 0\n",
      "\n",
      "Interest? Unknown\n",
      "Convoy\n",
      "---------------------------------\n",
      "Crew\n",
      "---------------------------------\n",
      "Cripton Technologies Inc.\n",
      "---------------------------------\n",
      "nonlinks:2\n",
      "headers:  11  URLs:  9\n",
      "link #:  0\n",
      "Cripton Technologies Inc | ZoomInfo.com\n",
      "https://www.zoominfo.com/c/cripton-technologies-inc/355342100\n",
      "-----------------------------------------\n",
      "link #:  1\n",
      "Cripton Technologies Inc. | VentureRadar\n",
      "https://www.ventureradar.com/.../Cripton%20Technologies%20Inc..._/43af5d96-d73b...\n",
      "-----------------------------------------\n",
      "link #:  2\n",
      "Crypton | Fabric Intelligence\n",
      "https://www.crypton.com/\n",
      "-----------------------------------------\n",
      "link #:  3\n",
      "Technologies | Crypton\n",
      "https://www.crypton.com/technologies/\n",
      "-----------------------------------------\n",
      "link #:  4\n",
      "Peter Cripton | Injury Biomechanics Engineer - Expert Witness | MEA ...\n",
      "https://www.meaforensic.com/.../peter-cripton-injury-biomechanical-engineer-expert-...\n",
      "-----------------------------------------\n",
      "link #:  5\n",
      "Krypton Capital: Turning ideas into successful ventures\n",
      "https://krypton.capital/\n",
      "-----------------------------------------\n",
      "link #:  6\n",
      "Krypton Technologies Limited | LinkedIn\n",
      "https://www.linkedin.com/company/krypton-technologies-limited\n",
      "-----------------------------------------\n",
      "link #:  7\n",
      "Crypton Ltd.: Private Company Information - Bloomberg\n",
      "https://www.bloomberg.com/research/stocks/private/snapshot.asp?privcapId...\n",
      "-----------------------------------------\n",
      "link #:  8\n",
      "Images for Cripton Technologies Inc.\n",
      "https://www.crunchbase.com/organization/crypton-tech-p-ltd\n",
      "-----------------------------------------\n",
      "Which link? 2\n",
      "\n",
      "Interest? Unknown\n",
      "Crisalix S[a]rl\n",
      "---------------------------------\n",
      "nonlinks:1\n",
      "headers:  11  URLs:  10\n",
      "link #:  0\n",
      "About us — Crisalix\n",
      "https://www.crisalix.com/en/about-us\n",
      "-----------------------------------------\n",
      "link #:  1\n",
      "Crisalix | VR 4D 3D plastic cosmetic surgery simulator software\n",
      "https://www.crisalix.com/\n",
      "-----------------------------------------\n",
      "link #:  2\n",
      "Crisalix | VR 4D 3D plastic cosmetic surgery simulator software\n",
      "https://www.crisalix.com/en/doctor\n",
      "-----------------------------------------\n",
      "link #:  3\n",
      "Customer care: Contact us — Crisalix\n",
      "https://www.crisalix.com/en/customer-care/contact\n",
      "-----------------------------------------\n",
      "link #:  4\n",
      "Crisalix | VR 4D 3D plastic cosmetic surgery simulator software\n",
      "https://www.crisalix.com/th\n",
      "-----------------------------------------\n",
      "link #:  5\n",
      "About us: Careers — Crisalix\n",
      "https://www.crisalix.com/en/about-us/careers\n",
      "-----------------------------------------\n",
      "link #:  6\n",
      "Crisalix 3D Simulator: Plans and pricing — Crisalix\n",
      "https://www.crisalix.com/en/prices\n",
      "-----------------------------------------\n",
      "link #:  7\n",
      "Crisalix SA Ltd.: Private Company Information - Bloomberg\n",
      "https://www.bloomberg.com/research/stocks/private/snapshot.asp?privcapId...\n",
      "-----------------------------------------\n",
      "link #:  8\n",
      "Crisalix Virtual Aesthetics | Rothaus Plastic Surgery | New York, NY\n",
      "https://www.rothausmd.com/introducing-crisalix/\n",
      "-----------------------------------------\n",
      "link #:  9\n",
      "Crisalix 3D - Dr. Michael Suzman\n",
      "https://drsuzman.com/Crisalix3D\n",
      "-----------------------------------------\n",
      "Which link? 1\n",
      "\n",
      "Interest? SHIT YES\n",
      "CrowdFlower\n",
      "---------------------------------\n",
      "CrowdStrike\n",
      "---------------------------------\n",
      "Cybereason\n",
      "---------------------------------\n",
      "Cylance\n",
      "---------------------------------\n",
      "Darktrace\n",
      "---------------------------------\n",
      "Deepmap\n",
      "---------------------------------\n",
      "Dia&Co\n",
      "---------------------------------\n",
      "Diamond Kinetics\n",
      "---------------------------------\n",
      "nonlinks:7\n",
      "headers:  13  URLs:  6\n",
      "link #:  0\n",
      "Diamond Kinetics – Engineering Better Players\n",
      "https://diamondkinetics.com/\n",
      "-----------------------------------------\n",
      "link #:  1\n",
      "Swingtracker\n",
      "https://www.amazon.com/Diamond-Kinetics-SwingTracker-Baseball.../B01MTK2211\n",
      "-----------------------------------------\n",
      "link #:  2\n",
      "Contact DK\n",
      "https://www.facebook.com › Places › Pittsburgh, Pennsylvania › Workplace & Office\n",
      "-----------------------------------------\n",
      "link #:  3\n",
      "PitchTracker\n",
      "https://www.crunchbase.com/organization/diamond-kinetics\n",
      "-----------------------------------------\n",
      "link #:  4\n",
      "Subscriptions\n",
      "https://blog.justbats.com/diamond-kinetics-vs.-zepp-swing-trackers\n",
      "-----------------------------------------\n",
      "link #:  5\n",
      "Support\n",
      "https://blastmotion.com/diamond-kinetics-trade-in/\n",
      "-----------------------------------------\n",
      "Which link? 0\n",
      "\n",
      "Interest? Unknown\n",
      "DigitalOcean\n",
      "---------------------------------\n",
      "Discord\n",
      "---------------------------------\n",
      "Docker\n",
      "---------------------------------\n",
      "nonlinks:8\n",
      "headers:  14  URLs:  6\n",
      "link #:  0\n",
      "Docker: Enterprise Container Platform\n",
      "https://www.docker.com/\n",
      "-----------------------------------------\n",
      "link #:  1\n",
      "Docker Documentation\n",
      "https://twitter.com/Docker\n",
      "-----------------------------------------\n",
      "link #:  2\n",
      "Docker Engine\n",
      "https://en.wikipedia.org/wiki/Docker_(software)\n",
      "-----------------------------------------\n",
      "link #:  3\n",
      "Docker Desktop\n",
      "https://www.zdnet.com/article/what-is-docker-and-why-is-it-so-darn-popular/\n",
      "-----------------------------------------\n",
      "link #:  4\n",
      "Docker containers\n",
      "https://opensource.com/resources/what-docker\n",
      "-----------------------------------------\n",
      "link #:  5\n",
      "Get Started\n",
      "https://aws.amazon.com/docker/\n",
      "-----------------------------------------\n",
      "Which link? 0\n",
      "\n",
      "Interest? sure\n",
      "DorsaVi\n",
      "---------------------------------\n",
      "nonlinks:8\n",
      "headers:  14  URLs:  6\n",
      "link #:  0\n",
      "dorsaVi Global - Wearable Sensor Technology & Movement Assessment\n",
      "https://www.dorsavi.com/\n",
      "-----------------------------------------\n",
      "link #:  1\n",
      "Revolutionary wearable ...\n",
      "https://www.youtube.com/channel/UCYIpd6S8pOa4xTuEyx8l6LA\n",
      "-----------------------------------------\n",
      "link #:  2\n",
      "ViPerform\n",
      "https://www.devdorsavi.com/\n",
      "-----------------------------------------\n",
      "link #:  3\n",
      "AU\n",
      "https://www.bloomberg.com/research/stocks/private/snapshot.asp?privcapid...\n",
      "-----------------------------------------\n",
      "link #:  4\n",
      "About\n",
      "https://www.meyerpt.com/dorsavi-movement-suite\n",
      "-----------------------------------------\n",
      "link #:  5\n",
      "dorsaVi | Revolutionary ...\n",
      "https://www.linkedin.com/company/dorsavi\n",
      "-----------------------------------------\n",
      "Which link? 0\n",
      "\n",
      "Interest? sure\n",
      "Dote\n",
      "---------------------------------\n",
      "Duo Security\n",
      "---------------------------------\n",
      "nonlinks:7\n",
      "headers:  16  URLs:  9\n",
      "link #:  0\n",
      "Duo Security: Duo Unified Access Security (UAS)\n",
      "https://duo.com/\n",
      "-----------------------------------------\n",
      "link #:  1\n",
      "Pricing\n",
      "https://twitter.com/duosec\n",
      "-----------------------------------------\n",
      "link #:  2\n",
      "Unified Access Security\n",
      "https://www.crunchbase.com/organization/duo-security\n",
      "-----------------------------------------\n",
      "link #:  3\n",
      "Blog\n",
      "https://techcrunch.com/2018/08/02/cisco-is-buying-duo-security-for-2-35b-in-cash/\n",
      "-----------------------------------------\n",
      "link #:  4\n",
      "Multi-Factor Authentication\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://play.google.com/store/apps/details?id=com.duosecurity.duomobile&hl=en...\n",
      "-----------------------------------------\n",
      "link #:  5\n",
      "Duo Account\n",
      "https://searchsecurity.techtarget.com/definition/Duo-Security\n",
      "-----------------------------------------\n",
      "link #:  6\n",
      "Guide to Two-Factor ...\n",
      "https://admin.duosecurity.com/login\n",
      "-----------------------------------------\n",
      "link #:  7\n",
      "Duo Security (@duosec) · Twitter\n",
      "information.rsa.com/SecurID_Access\n",
      "-----------------------------------------\n",
      "link #:  8\n",
      "Duo Security | Crunchbase\n",
      "www.okta.com/Gartner\n",
      "-----------------------------------------\n",
      "Which link? 0\n",
      "\n",
      "Interest? sure\n",
      "Earny\n",
      "---------------------------------\n",
      "Elomatic\n",
      "---------------------------------\n",
      "nonlinks:2\n",
      "headers:  11  URLs:  9\n",
      "link #:  0\n",
      "EL-O-Matic Valve Actuators | Emerson US\n",
      "https://www.emerson.com/en-us/automation/el-o-matic\n",
      "-----------------------------------------\n",
      "link #:  1\n",
      "Consulting & Engineering • Elomatic\n",
      "https://www.elomatic.com/en/\n",
      "-----------------------------------------\n",
      "link #:  2\n",
      "Elomatic - Wikipedia\n",
      "https://en.wikipedia.org/wiki/Elomatic\n",
      "-----------------------------------------\n",
      "link #:  3\n",
      "El-O-Matic Pneumatic, Electric Actuators - Valve Automation Actuators ...\n",
      "https://flowsysinc.com/products/actuators/elomatic/\n",
      "-----------------------------------------\n",
      "link #:  4\n",
      "Images for Elomatic\n",
      "https://www.amazon.com/EL-O-MATIC/pages/9515220011\n",
      "-----------------------------------------\n",
      "link #:  5\n",
      "Amazon.com: EL-O-MATIC\n",
      "www2.emersonprocess.com/en-US/brands/elomatic/products/.../Pages/E-Series.aspx\n",
      "-----------------------------------------\n",
      "link #:  6\n",
      "EL-O-Matic E-Series Rack and Pinion Pneumatic Valve Actuator | EMR\n",
      "https://www.spartancontrols.com/applied-technology/valves/isolate/.../el-o-matic/\n",
      "-----------------------------------------\n",
      "link #:  7\n",
      "El-O-Matic I On Off Actuator - Spartan Controls\n",
      "www.poonawallagroup.com/elomatic/contents/pne.htm\n",
      "-----------------------------------------\n",
      "link #:  8\n",
      "Pneumatic Actuators manufactured in India by Elomatic\n",
      "www.poonawallagroup.com/elomatic/contents/ddealers.htm\n",
      "-----------------------------------------\n",
      "Which link? 1\n",
      "\n",
      "Interest? meh\n",
      "Engage Biomechanics\n",
      "---------------------------------\n",
      "nonlinks:3\n",
      "headers:  11  URLs:  8\n",
      "link #:  0\n",
      "Engage Biomechanics Inc. | Markham, ON, Canada Startup - Gust\n",
      "https://gust.com/companies/engage_biomechanics_inc\n",
      "-----------------------------------------\n",
      "link #:  1\n",
      "Professor Andrew Eckford – Department of Electrical Engineering and ...\n",
      "www.andreweckford.com/\n",
      "-----------------------------------------\n",
      "link #:  2\n",
      "Engage Biomechanics - Markham, Ontario - Local Business | Facebook\n",
      "https://www.facebook.com/pages/Engage-Biomechanics/156234784585442\n",
      "-----------------------------------------\n",
      "link #:  3\n",
      "Images for Engage Biomechanics\n",
      "https://twitter.com/engagebio?lang=en\n",
      "-----------------------------------------\n",
      "link #:  4\n",
      "Engage Biomechanics (@EngageBio) | Twitter\n",
      "https://www2.bc.edu/christopher-kenaley/bio5380/\n",
      "-----------------------------------------\n",
      "link #:  5\n",
      "BIO5380 ~ Home\n",
      "https://app.oxfordabstracts.com/events/123/sessions/725/download\n",
      "-----------------------------------------\n",
      "link #:  6\n",
      "Videos\n",
      "https://www.pressreader.com/usa/yoga-journal/20180709/282282436030830\n",
      "-----------------------------------------\n",
      "link #:  7\n",
      "Public engagement with biomechanics - Oxford Abstracts\n",
      "https://www.noraxon.com/engage/\n",
      "-----------------------------------------\n",
      "Which link? 99\n",
      "Entelo\n",
      "---------------------------------\n",
      "Evidence Based Orthopedics NZ\n",
      "---------------------------------\n",
      "nonlinks:-1\n",
      "link #:  0\n",
      "Scholarly articles for Evidence Based Orthopedics NZ\n",
      "Allegranzi\n",
      "-----------------------------------------\n",
      "link #:  1\n",
      "Evidence-Based Orthopedics, 9781405184762 - medical books (nz)\n",
      "Mourad\n",
      "-----------------------------------------\n",
      "link #:  2\n",
      "A Review of the National Orthopaedic Enhanced Recovery after ...\n",
      "van Tulder\n",
      "-----------------------------------------\n",
      "link #:  3\n",
      "Evidence-based Orthopedics | Orthopedics | Surgery & Surgical ...\n",
      "medicalbooks.co.nz/.../m.../orthopaedics/evidence-based-orthopedics-978140518476...\n",
      "-----------------------------------------\n",
      "link #:  4\n",
      "Department of Orthopaedic Surgery and Musculoskeletal Medicine ...\n",
      "https://www.health.govt.nz/.../final-eras-quality-improvement-collaborative-aug11.do...\n",
      "-----------------------------------------\n",
      "link #:  5\n",
      "Health Quality & Safety Commission | 2017 evidence base\n",
      "https://www.wiley.com/en-us/Evidence+based+Orthopedics-p-9781405184762\n",
      "-----------------------------------------\n",
      "link #:  6\n",
      "Perioperative care in hip and knee arthroplasty—a survey of New ...\n",
      "https://www.otago.ac.nz/christchurch/departments/orthomsm/\n",
      "-----------------------------------------\n",
      "link #:  7\n",
      "Welcome to New Zealand Orthopaedic Association | New Zealand ...\n",
      "https://www.hqsc.govt.nz/our-programmes/reducing-harm.../2017-evidence-base/\n",
      "-----------------------------------------\n",
      "link #:  8\n",
      "How to become an Orthopaedic Surgeon | New Zealand Orthopaedic ...\n",
      "https://www.nzma.org.nz/journal/read-the-journal/all-issues/2010...no.../6718\n",
      "-----------------------------------------\n",
      "link #:  9\n",
      "Many operations are no better than placebo, says top surgeon - The ...\n",
      "nzoa.org.nz/\n",
      "-----------------------------------------\n",
      "link #:  10\n",
      "Searches related to Evidence Based Orthopedics NZ\n",
      "https://nzoa.org.nz/how-become-orthopaedic-surgeon\n",
      "-----------------------------------------\n",
      "link #:  11\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-819f47cf3858>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0melement_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'link #: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melement_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melement_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-----------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "browser = webdriver.Chrome('../../Garage/chromedriver')                     # Launches Browser\n",
    "\n",
    "for row in range(len(techies)):                                               # for num of techies\n",
    "    Firm = techies['Firm'][row]\n",
    "    Site = techies['Site'][row]\n",
    "    if Site == 'empty':\n",
    "        print(Firm)\n",
    "        print('---------------------------------')\n",
    "        browser.get('https://www.google.com/')                              # Get Google.com\n",
    "        search = browser.find_element_by_name(\"q\")                              \n",
    "        search.send_keys(str(Firm))                                         # Input firm into search\n",
    "        search.submit() \n",
    "        headers = browser.find_elements_by_css_selector('h3')               # List of title elements\n",
    "        urls = browser.find_elements_by_css_selector('cite')                # List of urls\n",
    "\n",
    "        # This is to attempt linning up the start of the h3's with the site links properly\n",
    "        nonlinks = len(headers) - len(urls)                                 \n",
    "        print('nonlinks:' + str(nonlinks))\n",
    "        if nonlinks > 0:\n",
    "            for fixes in range(nonlinks):\n",
    "                [\"no attached URL \" + str(fixes)] + urls\n",
    "            print('headers: ', len(headers),' URLs: ', len(urls))\n",
    "\n",
    "        \n",
    "        for element_num in range(len(urls)):\n",
    "            print('link #: ', element_num)\n",
    "            print(headers[element_num].text)\n",
    "            print(urls[element_num].text)\n",
    "            print(\"-----------------------------------------\")\n",
    "        chosen_link                  = int(input(prompt='Which link? '))\n",
    "        if chosen_link == 99:\n",
    "            techies['Site'][row]         = 'Unknown'\n",
    "            techies['What They do'][row] = 'Unknown'\n",
    "            techies['Interest'][row]     = 'Unknown'\n",
    "        else:\n",
    "            techies['Site'][row]         = urls[chosen_link].text\n",
    "            techies['What They do'][row] = headers[chosen_link].text\n",
    "            print('')\n",
    "            interest                     = input(prompt = 'Interest? ')\n",
    "            techies['Interest'][row]     = interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "techies.to_csv('../../job_search/Potential Techies.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out Google searching code on Craigslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(url, ):\n",
    "    browser.get('https://sfbay.craigslist.org/d/software-qa-dba-etc/search/sof')# Get Search page of Craigslist\n",
    "    search = browser.find_element_by_id(\"query\")                                # Locate searchbar\n",
    "    search.send_keys(term)                                                      # Input search\n",
    "    search.submit() \n",
    "    results = browser.find_elements_by_class_name('result-title')               # List of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = ['data', 'analyst', 'data scientist']\n",
    "list_of_dicts = []\n",
    "obtained_posts = []\n",
    "all_raw_info = []\n",
    "\n",
    "browser = webdriver.Chrome('../Garage/chromedriver')                     # Launches Browser\n",
    "for term in search_terms:\n",
    "    browser.get('https://sfbay.craigslist.org/d/software-qa-dba-etc/search/sof')# Get Search page of Craigslist\n",
    "    search = browser.find_element_by_id(\"query\")                                # Locate searchbar\n",
    "    search.send_keys(term)                                                      # Input search\n",
    "    search.submit() \n",
    "    results = browser.find_elements_by_class_name('result-title')               # List of results\n",
    "    for i in range(len(results)):                                               # for # of pages in list\n",
    "        results[i].click()                                                      # Click on Title i\n",
    "        post_HTML = browser.page_source\n",
    "        body_text = browser.find_element_by_id('postingbody').text\n",
    "        coordinates = re.findall('itude=\"[-0-9.]+\"', post_HTML)\n",
    "        post_code = re.findall('\\/[0-9]+\\.html', post_HTML)[0][1:-5]\n",
    "        if post_code not in obtained_posts:\n",
    "            post_dict = {\n",
    "                \"title\"     : browser.find_element_by_id('titletextonly').text,\n",
    "                \"body_text\" : body_text,\n",
    "                \"link\"      : re.findall('https[-A-za-z:\\/.0-9?=&;]+', body_text),\n",
    "                \"tags\"      : browser.find_element_by_class_name('attrgroup').text,\n",
    "                \"post_code\" : post_code\n",
    "            }\n",
    "            try:\n",
    "                post_dict[\"latitude\"]  = coordinates[0][7:-1]\n",
    "                post_dict[\"longitude\"] = coordinates[1][7:-1]\n",
    "            except:\n",
    "                pass\n",
    "            obtained_posts.append(post_dict['post_code'])\n",
    "            all_raw_info.append(post_HTML)\n",
    "            list_of_dicts.append(post_dict)\n",
    "        browser.back()                                            # Back\n",
    "        results = browser.find_elements_by_class_name('result-title')\n",
    "\n",
    "craigslist_df = pd.DataFrame(list_of_dicts, columns = [\n",
    "            \"title\", \"body_text\", \"tags\", \"link\",\n",
    "            \"latitude\", \"longitude\", \"post_code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "craigslist_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#craigslist_df['tags']\n",
    "#craigslist_df['tags'].map(lambda x: x.split('\\n')[0] for )\n",
    "def tag_column(row):\n",
    "    listed = row.split('\\n')\n",
    "    return listed[0].replace('compensation: ', '')\n",
    "craigslist_df['salary'] = craigslist_df['tags'].map(lambda x: tag_column(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_column(row):\n",
    "    listed = row.split('\\n')\n",
    "    if listed[1][0:15] == 'employment type':\n",
    "        return listed[1][17:]\n",
    "    else:\n",
    "        return 'UNLISTED'\n",
    "    #return listed[1][17:]#.replace('compensation: ', '')\n",
    "craigslist_df['time'] = craigslist_df['tags'].map(lambda x: tag_column(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_column(row):\n",
    "    listed = row.split('\\n')\n",
    "    if len(listed) == 3:\n",
    "        if listed[2] == 'telecommuting okay':\n",
    "            return 1\n",
    "    else:\n",
    "        return 0\n",
    "    #return listed[1][17:]#.replace('compensation: ', '')\n",
    "craigslist_df['remote_available'] = craigslist_df['tags'].map(lambda x: tag_column(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tag_column(row):\n",
    "    listed_tags = row.split('\\n')\n",
    "    if len(listed_tags) == 3:\n",
    "        if listed_tags[2] == 'non-profit organization':\n",
    "            return 1\n",
    "    else:\n",
    "        return 0\n",
    "craigslist_df['non_profit'] = craigslist_df['tags'].map(lambda x: tag_column(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DOE                                                                          26\n",
       "80,000-160,000                                                               20\n",
       "23/hr                                                                        20\n",
       "Competitive                                                                   4\n",
       "Will discuss with applicant.                                                  3\n",
       "Depending on Experience                                                       2\n",
       "DOE (Medical, Dental, Vision, 401k, PTO)                                      2\n",
       "hourly pay of $30 - $40, depending on experience                              2\n",
       "Hourly Rate                                                                   2\n",
       "Based on experience                                                           2\n",
       "varies                                                                        1\n",
       "$26 - $30 per hour                                                            1\n",
       "Please respond with a resume, short cover letter, and your desired salary     1\n",
       "Hourly rate                                                                   1\n",
       "130,000 - 175,000                                                             1\n",
       "$100k+ salary + vacation/sick/medical/dental + monthly commuter stipend       1\n",
       "market standard                                                               1\n",
       "50                                                                            1\n",
       "Salary, Stock Options, Healthcare and Benefits                                1\n",
       "Market Competitive                                                            1\n",
       "depends on experience                                                         1\n",
       "Base + Performance based Incentive + Generous Stock Options                   1\n",
       "100k-160k                                                                     1\n",
       "150k-175/ salary plus early stage equity                                      1\n",
       "Competitive market compensation with equity                                   1\n",
       "$29/hour plus benefits                                                        1\n",
       "Salary + Benefits                                                             1\n",
       "$32 - $35 per hour                                                            1\n",
       "150-180k, benefits, startup equity                                            1\n",
       "D.O.E.                                                                        1\n",
       "Available upon request                                                        1\n",
       "competitive                                                                   1\n",
       "150K to 175K with 5-15% bonus on top                                          1\n",
       "$114,432 - $139,104 Annually                                                  1\n",
       "Please refer to job posting                                                   1\n",
       "Name: salary, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "craigslist_df['salary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_dict = {\n",
    "    \"Will discuss with applicant.\" : \"DOE\",\n",
    "    'Depending on Experience'      : \"DOE\",\n",
    "    'Based on experience'          : \"DOE\",\n",
    "    'D.O.E.'                       : \"DOE\",\n",
    "    \"depends on experience\"        : \"DOE\",\n",
    "    'DOE (Medical, Dental, Vision, 401k, PTO)' : \"DOE + Benefits\"\n",
    "    'Will discuss with applicant.' :\"Unspecified\",\n",
    "    'varies'\n",
    "    \"Hourly Rate\" : \"Unspecified Hourly\"\n",
    "    'Hourly rate' : \"Unspecified Hourly\"\n",
    "    'competitive' : \"Unspecified\"\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "# \"Refused to specify\" is worded strongly because I hypothesize that this category \n",
    "# might get a red flag for people who I might not want to work for.  There are a lot of \n",
    "# Arguments about breaking down the social phopaws about how we hide our salary information \n",
    "# and how doing so benefits advantagious companies and does a great disservice to helping \n",
    "# bridge the pay gap between race/gender/etc.\n",
    "\n",
    "\n",
    "# Psudocode for making this easier:\n",
    "# Create table of just 2 columns, one for the things people put and the other for what it should be translated to.\n",
    "# Have the function go through each entry in the scrape and compair it to the first column.\n",
    "# If not in 1st column then it asks us which category to put it in.\n",
    "# If it's a specified number then have that be it's own special option that'll fill in another column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body_text</th>\n",
       "      <th>tags</th>\n",
       "      <th>link</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>post_code</th>\n",
       "      <th>salary</th>\n",
       "      <th>time</th>\n",
       "      <th>remote_available</th>\n",
       "      <th>non_profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Software Engineer (Data Warehouse Archi...</td>\n",
       "      <td>East Bay Municipal Utility District (EBMUD) in...</td>\n",
       "      <td>compensation: $114,432 - $139,104 Annually\\nem...</td>\n",
       "      <td>[]</td>\n",
       "      <td>37.795723</td>\n",
       "      <td>-122.257376</td>\n",
       "      <td>6764531895</td>\n",
       "      <td>$114,432 - $139,104 Annually</td>\n",
       "      <td>full-time</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Fellowship</td>\n",
       "      <td>What is Pathrise\\nPathrise (YC W18) invests in...</td>\n",
       "      <td>compensation: 80,000-160,000\\nemployment type:...</td>\n",
       "      <td>[https://www.pathrise.com/?utm_source=CLSFData...</td>\n",
       "      <td>37.791500</td>\n",
       "      <td>-122.401800</td>\n",
       "      <td>6763971146</td>\n",
       "      <td>80,000-160,000</td>\n",
       "      <td>full-time</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sales Data Analyst</td>\n",
       "      <td>AssetMark\\nSales Data Analyst\\nJob Label: ASMK...</td>\n",
       "      <td>compensation: DOE\\nemployment type: full-time</td>\n",
       "      <td>[https://hiring.accolo.com/jobs/Concord/Califo...</td>\n",
       "      <td>38.034903</td>\n",
       "      <td>-122.026918</td>\n",
       "      <td>6763769675</td>\n",
       "      <td>DOE</td>\n",
       "      <td>full-time</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python Programmer &amp; Data Analyst Administrator</td>\n",
       "      <td>Nordic Naturals\\nPython Programmer &amp; Data Anal...</td>\n",
       "      <td>compensation: DOE\\nemployment type: full-time</td>\n",
       "      <td>[https://app.hiremojo.com/jobs/Watsonville/Cal...</td>\n",
       "      <td>36.919956</td>\n",
       "      <td>-121.742343</td>\n",
       "      <td>6760663335</td>\n",
       "      <td>DOE</td>\n",
       "      <td>full-time</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Infrastructure Engineer</td>\n",
       "      <td>Our Culture\\n\\n\\n\\nThe San Francisco Chronicle...</td>\n",
       "      <td>compensation: 150-180k, benefits, startup equi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>37.786400</td>\n",
       "      <td>-122.389200</td>\n",
       "      <td>6759380827</td>\n",
       "      <td>150-180k, benefits, startup equity</td>\n",
       "      <td>full-time</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Senior Software Engineer (Data Warehouse Archi...   \n",
       "1                            Data Science Fellowship   \n",
       "2                                 Sales Data Analyst   \n",
       "3     Python Programmer & Data Analyst Administrator   \n",
       "4                       Data Infrastructure Engineer   \n",
       "\n",
       "                                           body_text  \\\n",
       "0  East Bay Municipal Utility District (EBMUD) in...   \n",
       "1  What is Pathrise\\nPathrise (YC W18) invests in...   \n",
       "2  AssetMark\\nSales Data Analyst\\nJob Label: ASMK...   \n",
       "3  Nordic Naturals\\nPython Programmer & Data Anal...   \n",
       "4  Our Culture\\n\\n\\n\\nThe San Francisco Chronicle...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  compensation: $114,432 - $139,104 Annually\\nem...   \n",
       "1  compensation: 80,000-160,000\\nemployment type:...   \n",
       "2      compensation: DOE\\nemployment type: full-time   \n",
       "3      compensation: DOE\\nemployment type: full-time   \n",
       "4  compensation: 150-180k, benefits, startup equi...   \n",
       "\n",
       "                                                link   latitude    longitude  \\\n",
       "0                                                 []  37.795723  -122.257376   \n",
       "1  [https://www.pathrise.com/?utm_source=CLSFData...  37.791500  -122.401800   \n",
       "2  [https://hiring.accolo.com/jobs/Concord/Califo...  38.034903  -122.026918   \n",
       "3  [https://app.hiremojo.com/jobs/Watsonville/Cal...  36.919956  -121.742343   \n",
       "4                                                 []  37.786400  -122.389200   \n",
       "\n",
       "    post_code                              salary       time  \\\n",
       "0  6764531895        $114,432 - $139,104 Annually  full-time   \n",
       "1  6763971146                      80,000-160,000  full-time   \n",
       "2  6763769675                                 DOE  full-time   \n",
       "3  6760663335                                 DOE  full-time   \n",
       "4  6759380827  150-180k, benefits, startup equity  full-time   \n",
       "\n",
       "   remote_available  non_profit  \n",
       "0               0.0         0.0  \n",
       "1               1.0         NaN  \n",
       "2               0.0         0.0  \n",
       "3               0.0         0.0  \n",
       "4               0.0         0.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "craigslist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote available\n",
      "remote available\n",
      "remote available\n",
      "remote available\n",
      "remote available\n",
      "non-profit\n",
      "remote available\n",
      "remote available\n",
      "non-profit\n",
      "non-profit\n",
      "remote available\n",
      "remote available\n",
      "remote available\n",
      "remote available\n",
      "remote available\n",
      "remote available\n",
      "remote available\n",
      "remote available\n",
      "remote available\n",
      "remote available\n",
      "remote available\n",
      "remote available\n",
      "remote available\n",
      "remote available\n",
      "remote available\n"
     ]
    }
   ],
   "source": [
    "for row in craigslist_df['tags']:\n",
    "    listed_tags = row.split('\\n')\n",
    "    if len(listed_tags) == 3:\n",
    "        if listed_tags[2] == 'telecommuting okay':\n",
    "            print('remote available')\n",
    "        if listed_tags[2] == 'non-profit organization':\n",
    "            print('non-profit')\n",
    "    elif len(listed_tags) > 3:\n",
    "        print('many tags')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body_text</th>\n",
       "      <th>tags</th>\n",
       "      <th>link</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>post_code</th>\n",
       "      <th>salary</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python Programmer &amp; Data Analyst Administrator</td>\n",
       "      <td>Nordic Naturals\\nPython Programmer &amp; Data Anal...</td>\n",
       "      <td>compensation: DOE\\nemployment type: full-time</td>\n",
       "      <td>[https://app.hiremojo.com/jobs/Watsonville/Cal...</td>\n",
       "      <td>36.919956</td>\n",
       "      <td>-121.742343</td>\n",
       "      <td>6760663335</td>\n",
       "      <td>DOE</td>\n",
       "      <td>full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Infrastructure Engineer</td>\n",
       "      <td>Our Culture\\n\\n\\n\\nThe San Francisco Chronicle...</td>\n",
       "      <td>compensation: 150-180k, benefits, startup equi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>37.786400</td>\n",
       "      <td>-122.389200</td>\n",
       "      <td>6759380827</td>\n",
       "      <td>150-180k, benefits, startup equity</td>\n",
       "      <td>full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Fellowship</td>\n",
       "      <td>What is Pathrise\\nPathrise (YC W18) invests in...</td>\n",
       "      <td>compensation: 80,000-160,000\\nemployment type:...</td>\n",
       "      <td>[https://www.pathrise.com/?utm_source=CLSFData...</td>\n",
       "      <td>37.791500</td>\n",
       "      <td>-122.401800</td>\n",
       "      <td>6758179207</td>\n",
       "      <td>80,000-160,000</td>\n",
       "      <td>full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>Develop a highly scalable, reliable, and real-...</td>\n",
       "      <td>compensation: DOE\\nemployment type: full-time</td>\n",
       "      <td>[]</td>\n",
       "      <td>37.762100</td>\n",
       "      <td>-122.397100</td>\n",
       "      <td>6757863516</td>\n",
       "      <td>DOE</td>\n",
       "      <td>full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tutor wanted, teach data science, python and S...</td>\n",
       "      <td>Tutor wanted, for a student pursuing master de...</td>\n",
       "      <td>compensation: 50\\nemployment type: employee's ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>37.348300</td>\n",
       "      <td>-121.984400</td>\n",
       "      <td>6757296715</td>\n",
       "      <td>50</td>\n",
       "      <td>employee's choice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0     Python Programmer & Data Analyst Administrator   \n",
       "1                       Data Infrastructure Engineer   \n",
       "2                            Data Science Fellowship   \n",
       "3                                  Big Data Engineer   \n",
       "4  Tutor wanted, teach data science, python and S...   \n",
       "\n",
       "                                           body_text  \\\n",
       "0  Nordic Naturals\\nPython Programmer & Data Anal...   \n",
       "1  Our Culture\\n\\n\\n\\nThe San Francisco Chronicle...   \n",
       "2  What is Pathrise\\nPathrise (YC W18) invests in...   \n",
       "3  Develop a highly scalable, reliable, and real-...   \n",
       "4  Tutor wanted, for a student pursuing master de...   \n",
       "\n",
       "                                                tags  \\\n",
       "0      compensation: DOE\\nemployment type: full-time   \n",
       "1  compensation: 150-180k, benefits, startup equi...   \n",
       "2  compensation: 80,000-160,000\\nemployment type:...   \n",
       "3      compensation: DOE\\nemployment type: full-time   \n",
       "4  compensation: 50\\nemployment type: employee's ...   \n",
       "\n",
       "                                                link   latitude    longitude  \\\n",
       "0  [https://app.hiremojo.com/jobs/Watsonville/Cal...  36.919956  -121.742343   \n",
       "1                                                 []  37.786400  -122.389200   \n",
       "2  [https://www.pathrise.com/?utm_source=CLSFData...  37.791500  -122.401800   \n",
       "3                                                 []  37.762100  -122.397100   \n",
       "4                                                 []  37.348300  -121.984400   \n",
       "\n",
       "    post_code                              salary               time  \n",
       "0  6760663335                                 DOE          full-time  \n",
       "1  6759380827  150-180k, benefits, startup equity          full-time  \n",
       "2  6758179207                      80,000-160,000          full-time  \n",
       "3  6757863516                                 DOE          full-time  \n",
       "4  6757296715                                  50  employee's choice  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "craigslist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://app.hiremojo.com/jobs/Watsonville/California/Python_Full_Stack_Developer/464189487/job.htm?sourceType=9']\n",
      "[]\n",
      "['https://www.pathrise.com/?utm_source=CLSFData&utm_campaign=CLSFData&utm_medium=web']\n",
      "[]\n",
      "[]\n",
      "['https://www.pathrise.com/?utm_source=CLSFData&utm_campaign=CLSFData&utm_medium=web']\n",
      "['https://www.hireart.com/jobs/043306b7/apply', 'https://www.hireart.com/jobs/043306b7/apply', 'https://www.hireart.com/jobs/043306b7/apply']\n",
      "[]\n",
      "[]\n",
      "['https://www.pathrise.com/?utm_source=CLSFData&utm_campaign=CLSFData&utm_medium=web']\n",
      "['https://jobs.lever.co/nava/18efd1a1-d10e-4b80-9913-2e73fa642fdc/apply', 'https://jobs.lever.co/nava/18efd1a1-d10e-4b80-9913-2e73fa642fdc/apply']\n",
      "['https://asianart.snaphire.com/?job=11577CRG']\n",
      "[]\n",
      "['https://www.pathrise.com/?utm_source=CLSFData&utm_campaign=CLSFData&utm_medium=web']\n",
      "['https://www.hireart.com/jobs/11dba112/apply', 'https://www.hireart.com/jobs/11dba112/apply', 'https://www.hireart.com/jobs/11dba112/apply']\n",
      "[]\n",
      "[]\n",
      "['https://hiring.accolo.com/jobs/San_Jose/California/Senior_Software_Engineer/459765479/job.htm?sourceType=9']\n",
      "['https://www.innovint.us/', 'https://www.capterra.com/p/144038/InnoVint/']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['https://jobs.ourcareerpages.com/job/388041?source=craigslist&key=oPWkcKnb']\n",
      "['https://jobs.ourcareerpages.com/job/388041?source=craigslist&key=oPWkcKnb']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['https://www.pathrise.com/?utm_source=CLSFProduct&utm_campaign=CLSFProduct&utm_medium=web']\n",
      "['https://www.pathrise.com/?utm_source=CLSFSWE&utm_campaign=CLSFSWE&utm_medium=web']\n",
      "[]\n",
      "['https://wsgr.wd1.myworkdayjobs.com/en-US/WSGR/job/Palo-Alto/Senior-Software-Developer_R192']\n",
      "[]\n",
      "['https://www.pathrise.com/?utm_source=CLSFProduct&utm_campaign=CLSFProduct&utm_medium=web']\n",
      "['https://www.pathrise.com/?utm_source=CLSFSWE&utm_campaign=CLSFSWE&utm_medium=web']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['https://www.pathrise.com/?utm_source=CLSFProduct&utm_campaign=CLSFProduct&utm_medium=web']\n",
      "['https://www.pathrise.com/?utm_source=CLSFSWE&utm_campaign=CLSFSWE&utm_medium=web']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['https://recruit.zoho.com/recruit/Apply.na?digest=i6PU.vuz.5ozWV0os.9MdUi71ywPpENiz1c6h9Zs09A-&embedsource=Embed']\n",
      "[]\n",
      "['https://www.paycomonline.net/v4/ats/web.php/jobs/ViewJobDetails?job=5683&clientkey=4D4FD0CCF62EE221C2C35081F2D3F958']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['https://hire.withgoogle.com/public/jobs/infostarllccom/view/P_AAAAAAEAAKbEE10BDsonQB?trackingTag=craigslist']\n",
      "[]\n",
      "['https://www.surveymonkey.com/r/5LMQFH5']\n",
      "['https://www.beautylish.com/jobs?gh_jid=849521&gh_src=uxe7hn1']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['https://www.pathrise.com/?utm_source=CLSFProduct&utm_campaign=CLSFProduct&utm_medium=web']\n",
      "['https://www.hireart.com/jobs/b49ca9c9/apply', 'https://www.hireart.com/jobs/b49ca9c9/apply', 'https://www.hireart.com/jobs/b49ca9c9/apply']\n",
      "['https://www.pathrise.com/?utm_source=CLSFSWE&utm_campaign=CLSFSWE&utm_medium=web']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['https://cubic.wd1.myworkdayjobs.com/cubic_USA_careers/job/USA-Concord-CA/Customer-Relationship-Management--CRM--Administrator_REQ_14619', 'https://cubic.wd1.myworkdayjobs.com/cubic_USA_careers/job/USA-Concord-CA/Customer-Relationship-Management--CRM--Administrator_REQ_14619']\n",
      "[]\n",
      "[]\n",
      "['https://career4.successfactors.com/sfcareer/jobreqcareer?jobId=455&company=tfewines&username=']\n",
      "['https://career4.successfactors.com/sfcareer/jobreqcareer?jobId=455&company=tfewines&username=']\n",
      "['https://www.pathrise.com/?utm_source=CLSACSWE&utm_campaign=CLSACSWE&utm_medium=web']\n",
      "['https://career4.successfactors.com/sfcareer/jobreqcareer?jobId=455&company=tfewines&username=']\n",
      "['https://www.pathrise.com/?utm_source=CLSACSWE&utm_campaign=CLSACSWE&utm_medium=web']\n",
      "[]\n",
      "['https://www.paycomonline.net/v4/ats/web.php/jobs/ViewJobDetails?job=7386&clientkey=0A2A2B3498A92573DA13BE33E8BDD296']\n",
      "['https://www.pathrise.com/?utm_source=CLSACSWE&utm_campaign=CLSACSWE&utm_medium=web']\n",
      "['https://www.pathrise.com/?utm_source=CLSACSWE&utm_campaign=CLSACSWE&utm_medium=web']\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for row in craigslist_df['link']:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28    None\n",
       "29    None\n",
       "30    None\n",
       "31    None\n",
       "32    None\n",
       "33    None\n",
       "34    None\n",
       "35    None\n",
       "36    None\n",
       "37    None\n",
       "38    None\n",
       "39    None\n",
       "40    None\n",
       "41    None\n",
       "42    None\n",
       "43    None\n",
       "44    None\n",
       "45    None\n",
       "46    None\n",
       "47    None\n",
       "48    None\n",
       "49    None\n",
       "50    None\n",
       "51    None\n",
       "52    None\n",
       "53    None\n",
       "54    None\n",
       "55    None\n",
       "56    None\n",
       "57    None\n",
       "58    None\n",
       "59    None\n",
       "60    None\n",
       "61    None\n",
       "62    None\n",
       "63    None\n",
       "64    None\n",
       "65    None\n",
       "66    None\n",
       "67    None\n",
       "68    None\n",
       "Name: tags, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tag_org(row):\n",
    "    listed = row.split('\\n')\n",
    "    try: #listed[2]# ==False:#[0:15] == 'employment type':\n",
    "        pass#return listed[1][17:]\n",
    "    except:\n",
    "        return listed[2]\n",
    "    #return listed[1][17:]#.replace('compensation: ', '')\n",
    "#craigslist_df['time'] = \n",
    "craigslist_df['tags'].map(lambda x: tag_org(x))[28:69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda x: craigslist_df['tags'][x].split('\\n')[0])\n",
    "for x in column:\n",
    "    x = x.replace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching Ventureloop\n",
    "https://www.ventureloop.com/ventureloop/job_search.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching Indeed\n",
    " - One of Ari's top reccomendations\n",
    "https://www.indeed.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome('../Garage/chromedriver')\n",
    "browser.get('https://www.indeed.com/')# Get Search page of Craigslist\n",
    "\n",
    "#search = browser.find_element_by_id(\"query\")                                # Locate searchbar\n",
    "#search.send_keys(term)                                                      # Input search\n",
    "#search.submit() \n",
    "#results = browser.find_elements_by_class_name('result-title')               # List of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_in = browser.find_element_by_id(\"text-input-what\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_in.send_keys(\"data scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_in.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.find_element_by_xpath('//*[@id=\"SALARY_rbo\"]/ul/li[1]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indeed_url_1 = 'https://www.indeed.com/jobs?q=data+scientist+$80,000&l=Oakland,+CA&rbl=San+Francisco,+CA&jlid=6cf5e6d389fd6d6b&explvl=entry_level'\n",
    "indeed_url_2 = 'https://www.indeed.com/jobs?q=data+analyst+$80,000&l=Oakland,+CA&rbl=San+Francisco,+CA&jlid=6cf5e6d389fd6d6b&explvl=entry_level'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([i for i in browser.find_elements_by_class_name(\"turnstileLink\") if r'=\\d' in i.get_attribute('href')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "------------\n",
      "Security Analyst\n",
      "https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0D3UvD5kBSgX9r9tFJCI4OL-41vvae__bcle4uMSq30h36AcPbHjl9bcVWQE4zSRT4Kea7tbZ9xVc5H1TR7taI7MsIHqEo9VUQEGW8-GAKeGYzNKsWbyT6TKfeNwALuAb_yH5UMfENMih5Q0jRBkuLpqZDYzbtWmiUUSv5K02ba-KofgRR3daoZGLtEUt5Bf6EgIDCo5ptNm0dutXmuf7LguPeLp7j8lqD8vVh8cwGQWFmlDrW5joyRs9ck50yA6qu-p64T4vRQ0-kbYMkS9f9zhBUEgxlY2iDdqQ-n1YnaeaD8ZmOaDmf7w_nu3UVWLClCxEKIO-dHiWEs4xSOnX5nNNepqlC4veruew-TjjCe7Men7mjF6JtUFlEWT4aZW25f0sCwpq5Jxj03m4G5MkNHKKCPwopRg9HicnrLZZW3xHy9P9s7WFXs15KPNfl-3WHGP45iLwf0uEfpvWFobo_dZrpHejqzcqqrzvycpn_EWSFGfHr8_hXgF8qGgUFeFuich0EsjYIyRSrKmC3RNJ8KtRpf1T7L5u4=&vjs=3&p=1&sk=&fvj=0&tk=1cvs1gkutbqgp803&jsa=3165\n",
      "------------\n",
      "Business Data/Analytics Consultant(DBA5)\n",
      "https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0BoeDkTD_H99wsrPbGl8S8R9VezjVunTmvy3hNmICbxwttyQcywGqavB3biN5gVUe_DLQZOyReRaQ8-u3JjaTnXdSB5b3jKUhMfg2VrT6BAhYq_GwjWx9zwd0gHMMwc7RMy67b0pfXyzRzEsavzMFVyMphm__8Gx7Hkbb78_SeZ2iGg1UwNdFBTvyC1v9tgSnLLtrjiGxofIHJWqiZb1BlvtOFV0h8iwxN6dGHK_8QZ9zso0CswyC_-PdYGKnMQxtWqAJYHyz1P9Kf95QgutuTexb7_3TqAoijo1wNF8gojhm7D-Sy9_SlmTU_1b0Gk4CAhVF21VbyXGBdIurQSn1wXrNic0Z0XBHEl9cUJDSk7SpMk6CVWUoeHaMQOyPx0i8P-8-sO6sJhGrzSKvjTecmGG53eaw4BM8nXXbICNNxTVaycbrhmbf623Xmwu0GgVN5fA8n3tMSOrn_3QOqTlG_i&vjs=3&p=2&sk=&fvj=0&tk=1cvs1gkutbqgp803&jsa=3165\n",
      "------------\n",
      "ATR International, Inc.\n",
      "https://www.indeed.com/cmp/Atr-International,-Inc.\n",
      "------------\n",
      "36 reviews\n",
      "https://www.indeed.com/cmp/Atr-International,-Inc./reviews?campaignid=cmplinktst2&from=SERP&jt=Business+Data%5C%2FAnalytics+Consultant%28DBA5%29&fromjk=e8112e6754b5c0ff&jcid=3ac765140903218f\n",
      "------------\n",
      "Distributor Strategy Analyst\n",
      "https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0DElm3MIjlUSFLEFbpoE0cvkGwakGKRqLG0cDk9bPXCRz_cIwU4j3XX8iic71yr8ysmzrOEhDMUCanRkEl5N8SmLSiCoF0UuDFOTlq6NOtI-epkTXxD_qc4Sh7YBWqznfAp4DU023IJbUTjqqIKx5xlGVavL6GkhH0aalb4eXPV7jBUqiFpcM9B9Zk7RH4r7HsAe-bQ2Bi4bvr3e9_MRLlHQl21HX-rC05KEpxY35dpfHpUEc-v_MD8QlRI_JsajUsxHq8Ys7No7ax_8h9k9NUf0u7pYA6IwecioC1BVINHU45Cj9vGkCW41e9fvlabYPAT2VShL38eVYShT6cahuooSyDn4HO6F1JYG-OiShsV7X-KBZUcFqN5ny1SxexqPzfVO5ynzIV7QvhSJh4o-Ht1wyRZduc4kMOeI5I-_tet8PoosEqPnNjJLwgOEZ18zl_Pq8d8ct05Ta-gUpNyoo1U&vjs=3&p=3&sk=&fvj=0\n",
      "------------\n",
      "Constellation Brands\n",
      "https://www.indeed.com/cmp/Constellation-Brands\n",
      "------------\n",
      "165 reviews\n",
      "https://www.indeed.com/cmp/Constellation-Brands/reviews\n",
      "------------\n",
      "Sales Development Representative\n",
      "https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0AA2D8ancNxGAv5gHOd7xGplDSD410oMH8hBPRYRsgnxNvJahmVPmbPXeUXOMTKaUR54Y_ehD_76eDUAg_1045nqw3k49_e1v9ROdLTbILSEfBa8JhMr7KSBKAFQMDCTM8xMqdD_F3b917L3A-VkhoHg_S_9PNkW6L9w3CqkZ828VXbz9O3pA1fdVIsHk1-lm1oa1NK1hDAUUeL3mcHKmbjS9U9yk-6wYbvJGR586_zrFQ9EMgf3sfPm1JIHZukhyQAQjdLDDdMZ_d6ZNcxUZfDPD2PuciRDbxVBBqiaHd25F2C3GV3irCBm0IeJlSjfW78HEAWFv1QvwDyOg1i--PQ3B13LeascG3EixQkSW3IJYvmq7aRdu4XA93cmWm8zEyIAcq8e95m4PDsLgB497D7rL8rFWChm_OOoEtfH21tEBLsCUik91gAhpjCGcer9Jh_s4Q4jR2oWcWaeQ1VHa-w4FBIhLQCj_Y0sx6PsFcnli9ZVkdtyTgnkV4Z7F1aoNvgFpENrjsWtPF2acMnD1E2IocjWxo7ih-OYVHrYs6qMw==&vjs=3&p=4&sk=&fvj=0\n",
      "------------\n",
      "Research Data Analyst\n",
      "https://www.indeed.com/rc/clk?jk=f68f83d61fce3a83&fccid=2a341562d64c7cdb&vjs=3\n",
      "------------\n",
      "380 reviews\n",
      "https://www.indeed.com/cmp/University-of-California---SAN-Francisco/reviews\n",
      "------------\n",
      "Strategic Finance Data Analyst\n",
      "https://www.indeed.com/rc/clk?jk=f007a7a35d0179d8&fccid=8510f9bc3a085f8e&vjs=3\n",
      "------------\n",
      "27 reviews\n",
      "https://www.indeed.com/cmp/Dropbox/reviews\n",
      "------------\n",
      "Data Analyst / Scientist [Full-time or intern)]\n",
      "https://www.indeed.com/rc/clk?jk=c082ac9af5f83d12&fccid=d20eb56c8249d2ea&vjs=3\n",
      "------------\n",
      "Associate Analyst\n",
      "https://www.indeed.com/rc/clk?jk=99615a9ef900d37c&fccid=a5aed56af9f8dca9&vjs=3\n",
      "------------\n",
      "26 reviews\n",
      "https://www.indeed.com/cmp/Judicial-Council-of-California/reviews\n",
      "------------\n",
      "Business Intelligence Analyst\n",
      "https://www.indeed.com/rc/clk?jk=cc0bbd8d04cdb77e&fccid=f89deb5a97c7738a&vjs=3\n",
      "------------\n",
      "493 reviews\n",
      "https://www.indeed.com/cmp/Adobe/reviews\n",
      "------------\n",
      "Data Scientist\n",
      "https://www.indeed.com/rc/clk?jk=891c5ae5d3a7f7d3&fccid=2472edbe03e34796&vjs=3\n",
      "------------\n",
      "5 reviews\n",
      "https://www.indeed.com/cmp/Bolt/reviews\n",
      "------------\n",
      "Data Analyst\n",
      "https://www.indeed.com/rc/clk?jk=9c2c2b341ff58c84&fccid=e5b6b3bcf1a25114&vjs=3\n",
      "------------\n",
      "8 reviews\n",
      "https://www.indeed.com/cmp/Hoteltonight/reviews\n",
      "------------\n",
      "Business Data Analyst\n",
      "https://www.indeed.com/rc/clk?jk=7d18f05ea69552df&fccid=22d78e2095e9cf1a&vjs=3\n",
      "------------\n",
      "30 reviews\n",
      "https://www.indeed.com/cmp/Squaretrade/reviews\n",
      "------------\n",
      "Analyst, Data Scientist - Brighterion\n",
      "https://www.indeed.com/rc/clk?jk=80cc221986fbcd97&fccid=5da8ce8509b876cc&vjs=3\n",
      "------------\n",
      "24 reviews\n",
      "https://www.indeed.com/cmp/Brighterion/reviews\n",
      "------------\n",
      "Data Scientist\n",
      "https://www.indeed.com/rc/clk?jk=20b0aca7feb12498&fccid=25cda752a689f9b8&vjs=3\n",
      "------------\n",
      "307 reviews\n",
      "https://www.indeed.com/cmp/Esurance/reviews\n",
      "------------\n",
      "Analyst, Valuation Services\n",
      "https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0Dys7GhibF6Q9-lO7uuJ_sA_RJawJ0yQMZxksOn_UXT6UR6l6nYb47OSQ7745hTm0g0CbqKZzMBqwjwFjO2B_PLlTvW3WIO5mEZ1ABfD8qky8617KFp8lzaIcI-NvKWzLzWmdaE1Vg0ZS3lyJmNkJHhU0mUO-3g6tGBBgElqZCcRTVeB4EZRItoNMIp6iMdmBxp6HI6hcg_uch-fHMgk2k1FVfM78mMxslShtibD6-CQtjn2UKj5-binyFZHFaX8l7cM5-5o1JR0o-nQtmVJAw4jYZQLLQusMJdX-60tu3gglLOJ_X9O-El5Kg970smbuZimo7aXv5eiPXWWMD4YNnlHvrN1sHF7bDPJHKlQ5BtRPIOFpNfnXw8lg5yZiELMtP3Tj-fbyeO12C8sX2igPMTRynpikcqvZVJJZaA3UTqLXOakjXNj1OnFRpbBETFxlrcCgJHEgU3aavWlfhqPqWBc8fgQvG_Y1_EsarSBhRl0LSm-7y25coLuD6wOMS21f17xo47PN0UGrG39VSrjqK9I9qel6lUnJDriinRDwPFJOf5IHrH8yHfiqgVKvzEElV-St7g9SsJxr6ZMskTorU_Tzp1mJuRBOhAH9LfyNbPdOb8y4kFTqx5p4Lqp65BO8aR_a95pz72v66cdK4G70Wn9F4IVtS9brr4HV-u6Lb5XSF_nlGbPQPoMvQ0E17UNurpp-TwTLEHTy1yzgNQtZxwounEeEDaLfCzQPNHyKII6M0VtbYWandGReWC_b6oU4tM9qEPnB6AIFQ-0aeZF7S_r9jLiYYYNNqE05bdW2O3tyoF3O24Hmx8MKkX0a440iwjNQiN0uitxmR9hJf_QYxpSaL3v7fDSDbnNgkDx5Vq6VPqFsY9w49twSDVgKEfkUqFnDElFUAo7jYkunOtt5W9-9bLNDELumbgFNVY63vSZ0iWSAcbxpnBjJY2gAh2Rzqh0wXJ9DdBuzmBkxwODbhnL78LGOqwrJQ=&vjs=3&p=5&sk=&fvj=0\n",
      "------------\n",
      "DUFF AND PHELPS, LLC\n",
      "https://www.indeed.com/cmp/Duff-&-Phelps\n",
      "------------\n",
      "60 reviews\n",
      "https://www.indeed.com/cmp/Duff-&-Phelps/reviews\n",
      "------------\n",
      "Data Analyst – ChatBOT, Artificial Intelligence - 30879D\n",
      "https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0CD7B5JfRXwrS5u7vDn9tMfVX7MpTnOLmEhLa-oOxyH7BvwHI3HacQ8t4LPaSHt3yJy1x4Je8u7ao4PfiZqhb9W3ySUPv6NZU7JCtJGxgSNXmgCPzQ1ywuSa6tIzmcA_wDixIr3k6FB5gwHx4BZ8UTf0EQCJSHCIKLSdcfBrKfhi-Dd_ja3gLhESVt5ifZCgEGA10d1gjwZcwi5NlBCB5ksp-OcDRSpHCwQFqnqjhY0jakVUs_2YBNiLIQw8c4zKzf_gEbNrC-6Q3irMxnegwx_OtkP0GFXog-X8cZ7d_eE3Wh2iDrbXWrdV98nUQ2b0JyKsJEiumnHJLRdEnl7cskTIYfxpqpUTfx7rJC2Q6svXJDZvapy9l3xAf9UQGLxcAjqXPMuOo8Bpqi7xvXdMsOAM0JosZG3NqPDUWl6N2DXLjKUmbafLGvXZZIlL4abfXxmJfTjqnbpa6oP1WD7FDvvSMYuM2SezMHWJWvb8flRgw==&vjs=3&p=6&sk=&fvj=1&tk=1cvs1gkutbqgp803&jsa=3165\n"
     ]
    }
   ],
   "source": [
    "#postings = [i for i in browser.find_elements_by_class_name(\"turnstileLink\") if ]\n",
    "print(len(browser.find_elements_by_class_name(\"turnstileLink\")))\n",
    "for i in browser.find_elements_by_class_name(\"turnstileLink\"):\n",
    "    #if i.\n",
    "    print(\"------------\")\n",
    "    print(i.text)\n",
    "    print(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = ['data', 'analyst', 'data scientist']\n",
    "list_of_dicts = []\n",
    "obtained_posts = []\n",
    "all_raw_info = []\n",
    "\n",
    "browser = webdriver.Chrome('../Garage/chromedriver')                     # Launches Browser\n",
    "for term in search_terms:\n",
    "    browser.get('https://sfbay.craigslist.org/d/software-qa-dba-etc/search/sof')# Get Search page of Craigslist\n",
    "    search = browser.find_element_by_id(\"query\")                                # Locate searchbar\n",
    "    search.send_keys(term)                                                      # Input search\n",
    "    search.submit() \n",
    "    results = browser.find_elements_by_class_name('result-title')               # List of results\n",
    "    for i in range(len(results)):                                               # for # of pages in list\n",
    "        results[i].click()                                                      # Click on Title i\n",
    "        post_HTML = browser.page_source\n",
    "        body_text = browser.find_element_by_id('postingbody').text\n",
    "        coordinates = re.findall('itude=\"[-0-9.]+\"', post_HTML)\n",
    "        post_code = re.findall('\\/[0-9]+\\.html', post_HTML)[0][1:-5]\n",
    "        if post_code not in obtained_posts:\n",
    "            post_dict = {\n",
    "                \"title\"     : browser.find_element_by_id('titletextonly').text,\n",
    "                \"body_text\" : body_text,\n",
    "                \"link\"      : re.findall('https[-A-za-z:\\/.0-9?=&;]+', body_text),\n",
    "                \"tags\"      : browser.find_element_by_class_name('attrgroup').text,\n",
    "                \"post_code\" : post_code\n",
    "            }\n",
    "            try:\n",
    "                post_dict[\"latitude\"]  = coordinates[0][7:-1]\n",
    "                post_dict[\"longitude\"] = coordinates[1][7:-1]\n",
    "            except:\n",
    "                pass\n",
    "            obtained_posts.append(post_dict['post_code'])\n",
    "            all_raw_info.append(post_HTML)\n",
    "            list_of_dicts.append(post_dict)\n",
    "        browser.back()                                            # Back\n",
    "        results = browser.find_elements_by_class_name('result-title')\n",
    "\n",
    "craigslist_df = pd.DataFrame(list_of_dicts, columns = [\n",
    "            \"title\", \"body_text\", \"tags\", \"link\",\n",
    "            \"latitude\", \"longitude\", \"post_code\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching Upwork\n",
    "- Specifically for contract work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching Idealist\n",
    " - great for non-profits\n",
    " - https://www.idealist.org/en/?q=job&radius=160000&sort=relevance&type=JOB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching Glassdoor\n",
    " - Can come with salary research\n",
    " - https://www.glassdoor.com/index.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching Dice\n",
    " - Good for technical roles/jobs\n",
    "https://www.dice.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching Monster\n",
    "https://www.monster.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching Remote OK\n",
    " - Remote Job focus\n",
    "https://remoteok.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching We Work Remotely\n",
    " - Remote Job Focus\n",
    "https://weworkremotely.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = ['data', 'analyst']\n",
    "list_of_dicts = []\n",
    "obtained_posts = []\n",
    "all_raw_info = []\n",
    "\n",
    "browser = webdriver.Chrome('../Garage/chromedriver')                     # Launches Browser\n",
    "for term in search_terms:\n",
    "    browser.get('https://sfbay.craigslist.org/d/software-qa-dba-etc/search/sof')# Get Search page of Craigslist\n",
    "    search = browser.find_element_by_id(\"query\")                                # Locate searchbar\n",
    "    search.send_keys(term)                                                      # Input search\n",
    "    search.submit() \n",
    "    results = browser.find_elements_by_class_name('result-title')               # List of results\n",
    "    for i in range(len(results)):                                               # for # of pages in list\n",
    "        results[i].click()                                                      # Click on Title i\n",
    "        post_HTML = browser.page_source\n",
    "        body_text = browser.find_element_by_id('postingbody').text\n",
    "        coordinates = re.findall('itude=\"[-0-9.]+\"', post_HTML)\n",
    "        post_code = re.findall('\\/[0-9]+\\.html', post_HTML)[0][1:-5]\n",
    "        if post_code not in obtained_posts:\n",
    "            post_dict = {\n",
    "                \"title\"     : browser.find_element_by_id('titletextonly').text,\n",
    "                \"body_text\" : body_text,\n",
    "                \"link\"      : re.findall('https[-A-za-z:\\/.0-9?=&;]+', body_text),\n",
    "                \"tags\"      : browser.find_element_by_class_name('attrgroup').text,\n",
    "                \"post_code\" : post_code\n",
    "            }\n",
    "            try:\n",
    "                post_dict[\"latitude\"]  = coordinates[0][7:-1]\n",
    "                post_dict[\"longitude\"] = coordinates[1][7:-1]\n",
    "            except:\n",
    "                pass\n",
    "            obtained_posts.append(post_dict['post_code'])\n",
    "            all_raw_info.append(post_HTML)\n",
    "            list_of_dicts.append(post_dict)\n",
    "        browser.back()                                            # Back\n",
    "        results = browser.find_elements_by_class_name('result-title')\n",
    "\n",
    "craigslist_df = pd.DataFrame(list_of_dicts, columns = [\n",
    "            \"title\", \"body_text\", \"tags\", \"link\",\n",
    "            \"latitude\", \"longitude\", \"post_code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_answer(search_question)\n",
    "    browser.get('www.google.com')# Get Search page of Craigslist\n",
    "    search = browser.find_element_by_id(\"q\")                                # Locate searchbar\n",
    "    search.send_keys(search_question)                                                    # Input search\n",
    "    search.submit()\n",
    "    headers = browser.find_elements_by_css_selector('h3')               # List of title elements\n",
    "urls = browser.find_elements_by_css_selector('cite')                # List of urls\n",
    "\n",
    "# This is to attempt linning up the start of the h3's with the site links properly\n",
    "nonlinks = len(headers) - len(urls)                                 \n",
    "print('nonlinks:' + str(nonlinks))\n",
    "if nonlinks > 0:\n",
    "    for fixes in range(nonlinks):\n",
    "        [\"no attached URL \" + str(fixes)] + urls\n",
    "    print('headers: ', len(headers),' URLs: ', len(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer#, TfidfVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer, word_tokenize\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'[^a-zA-Z]',' ', text.lower())\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmer = WordNetLemmatizer()\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    return \" \".join([lemmer.lemmatize(word) for word in tokens if len(word) > 1 and not word in stop_words])\n",
    "cvec = CountVectorizer(analyzer = \"word\",\n",
    "                       tokenizer = tokenizer.tokenize,\n",
    "                       preprocessor = preprocess,\n",
    "                       stop_words = 'english',\n",
    "                       min_df = 1) # This can be a float representing it's proportion of the documents\n",
    "                       #max_df = None)\n",
    "                       #ngram_range = (min,max),\n",
    "                       #max_features = None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Viewing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Posting Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = \"\"\"Peerspace is creating a world where it’s easy to bring people together, starting with making it easy to find the perfect place to meet, create, and celebrate with others. Our Airbnb-like marketplace uncovers the world’s most unique spaces - like lofts, rooftops, and art galleries - and makes them ready to use for meetings, events, even filmshoots.\n",
    " \n",
    "Over 1 million people have come together in a Peerspace, and we’re looking for people who want to help us reach the next 10 million.\n",
    " \n",
    "We’re looking for a highly analytical Associate to join our growing Business Operations and Strategy team. BizOPs at Peerpsace is equal parts business strategy, operational improvement, and analytics. You’ll partner with functional leads to continually up-level the way we measure and analyze our performance and act on those insights.\n",
    "\n",
    "The ideal candidate loves data and business analytics, can synthesize complex insights into a simple message, and is very experienced in driving change through a collaborative approach.   \n",
    " \n",
    "Example projects include:\n",
    "-        Customer segmentation and feedback insights\n",
    "-        Modeling of market entry opportunities\n",
    "-        Strategies to scale operations teams\n",
    "-        Customer targeting and growth tactics\n",
    "-        Monthly performance analytics and improvement opportunities\n",
    "\n",
    "Responsibilities:\n",
    "End to end ownership of analytics projects, where you will help translate your insights into action across the business\n",
    "Develop new KPIs and use existing ones to identify, diagnose, and resolve performance issues\n",
    "Ownership over our data, including on-going and ad-hoc analytics/reporting\n",
    "Implement new operations process, and identify what new platform features will help our central functions scale effectively\n",
    "\n",
    "What you bring to the table:\n",
    "·        Bachelor’s degree, preferably in a highly quantitative discipline\n",
    "·        Minimum of 1-2 years of experience in management consulting, investment banking, tech strategy/finance, and/or business operations.\n",
    "·        Strong analytical skills and Excel proficiency\n",
    "·        Strong SQL experience\n",
    "·        Consumer internet experience and interest in e-commerce marketplaces\n",
    "·        Great at creating and analyzing business information, creating dashboards, tracking key business metrics and translating results into actionable deliverables, messages, and presentations\n",
    " \n",
    "Perks\n",
    "·        Join a team reshaping a $500B industry\n",
    "·        Competitive salary with employee stock options and access to a 401k\n",
    "·        Medical, dental, and vision coverage\n",
    "·        Take-it-when-you-need-it vacation and sick days\n",
    "·        A flexible work environment\n",
    "·        Dog-friendly office\n",
    "·        Weekly catered lunch\n",
    "·        $500 annual professional development allowance\n",
    "·        20% discount on all Peerspace bookings\n",
    " \n",
    "About Us:\n",
    "Peerspace is a community marketplace that makes planning gatherings - starting with finding the perfect space - simple. Whether it’s a loft for a party, a rooftop for a film shoot, or an art gallery for a meeting, Peerspace empowers people to create one-of-a-kind experiences at any price point. As a community marketplace, Peerspace makes it easy for individuals and businesses to monetize their underused space and share it with an audience of millions.\n",
    " \n",
    "Founded in April of 2014, Peerspace is headquartered in San Francisco, with offices in Los Angeles, New York, and Chicago. The company’s investors include GV and Foundation Capital.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploritory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Imports & Initiations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = \n",
    "X = df[features]\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Review & Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "import smtplib\n",
    "import re\n",
    "import urllib2\n",
    "import os.path\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "\n",
    "# Enable an options page that lets you choose whom to send/not to send\n",
    "\n",
    "CSV = 'csv'\n",
    "HTML = 'html'\n",
    "\n",
    "def clean(content):\n",
    "    content = re.sub(r',','#', content)\n",
    "    return re.sub(r\"\\n\", \"\", content)\n",
    "\n",
    "def generateFileName():\n",
    "    ROOT_DIR        = '~'\n",
    "    CSV             = \"CSV/\"\n",
    "    HTML            = 'HTML/'\n",
    "    file_prefix     = 'craigslist_'\n",
    "    file_number     = 1\n",
    "    csv_file_suffix = \".csv\"\n",
    "    html_file_suffix= \".html\"\n",
    "    HTML_FILENAME   = ROOT_DIR + HTML + file_prefix + str(file_number)\n",
    "    CSV_FILENAME    = ROOT_DIR + CSV  + file_prefix + str(file_number)\n",
    "    \n",
    "    # Increment the file number until we find one isn't used\n",
    "    while (os.path.exists(CSV_FILENAME)):\n",
    "        file_number  += 1\n",
    "        HTML_FILENAME = ROOT_DIR + HTML + file_prefix + str(file_number)\n",
    "        CSV_FILENAME  = ROOT_DIR + CSV  + file_prefix + str(file_number)\n",
    "    return {CSV: CSV_FILENAME, HTML: HTML_FILENAME}\n",
    "\n",
    "# EMAIL ADDRESS\n",
    "\n",
    "server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "server.starttls()\n",
    "server.login(email, emailpwd)\n",
    "server.sendmail(email, email, msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recycling Bin for Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #for i in headers:                                                       # For each in h3s\n",
    "        #    check = i[0:6]\n",
    "        #    if check == 'Images' or check == 'Videos':\n",
    "        #        print('nvm', i)\n",
    "        #        h3s.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6,10):\n",
    "    techies = techies.drop('Unnamed: ' + str(i), axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvm Images for butts\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-a7bbd3063f36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mh3s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_elements_by_css_selector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'h3'\u001b[0m\u001b[0;34m)\u001b[0m                   \u001b[0;31m# list of title elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh3s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m                                                       \u001b[0;31m# For each in h3s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh3s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Images'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Videos'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nvm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh3s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "Firm = 'butts'           # Yes, this was what I chose to test it with.\n",
    "browser = webdriver.Chrome('../../Garage/chromedriver') \n",
    "browser.get('https://www.google.com/')   \n",
    "search = browser.find_element_by_name(\"q\")                              \n",
    "search.send_keys(str(Firm))                                         # Input firm into search\n",
    "search.submit()\n",
    "h3s = browser.find_elements_by_css_selector('h3')                   # list of title elements\n",
    "for i in range(len(h3s)):     # For each in h3s\n",
    "    \n",
    "    check = h3s[i].text[0:6]\n",
    "    if check == 'Images' or check == 'Videos':\n",
    "        print('nvm', h3s[i].text)\n",
    "        h3s.pop(i)\n",
    "        \n",
    "print(h3s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
